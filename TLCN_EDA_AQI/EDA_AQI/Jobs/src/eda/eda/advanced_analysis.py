import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from minio import Minio
from io import BytesIO
import warnings
warnings.filterwarnings('ignore')

# =============================
# C·∫§U H√åNH MINIO
# =============================
MINIO_HOST = "172.27.91.163:9004"
MINIO_ACCESS_KEY = "admin"
MINIO_SECRET_KEY = "admin123"
MINIO_CLEAN_BUCKET = "air-quality-clean"

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Ph√¢n T√≠ch Ch·∫•t L∆∞·ª£ng Kh√¥ng Kh√≠ Chuy√™n S√¢u",
    page_icon="üåç",
    layout="wide"
)

# CSS cho styling
st.markdown("""
<style>
.metric-card {
    background-color: #f0f2f6;
    border-radius: 10px;
    padding: 20px;
    margin: 10px 0;
}
.pollution-high {
    color: #ff4444;
    font-weight: bold;
}
.pollution-moderate {
    color: #ffaa44;
    font-weight: bold;
}
.pollution-good {
    color: #44aa44;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

def get_minio_client():
    """T·∫°o MinIO client"""
    return Minio(
        MINIO_HOST,
        access_key=MINIO_ACCESS_KEY,
        secret_key=MINIO_SECRET_KEY,
        secure=False
    )

def list_combined_files(client, bucket):
    """Li·ªát k√™ c√°c file combined trong MinIO"""
    try:
        all_objects = list(client.list_objects(bucket, prefix="openmeteo/global/", recursive=True))
        combined_files = []
        for obj in all_objects:
            if 'combined' in obj.object_name.lower():
                combined_files.append(obj.object_name)
        return combined_files
    except Exception as e:
        st.error(f"L·ªói khi li·ªát k√™ files: {e}")
        return []

def load_csv_from_minio(client, bucket, path):
    """Load CSV t·ª´ MinIO"""
    try:
        response = client.get_object(bucket, path)
        data = response.read()
        response.close()
        response.release_conn()
        return pd.read_csv(BytesIO(data))
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i file {path}: {e}")
        return None

@st.cache_data
def load_data():
    """Load d·ªØ li·ªáu t·ª´ MinIO"""
    try:
        client = get_minio_client()
        
        # Ki·ªÉm tra bucket t·ªìn t·∫°i
        if not client.bucket_exists(MINIO_CLEAN_BUCKET):
            st.error(f"‚ùå Bucket '{MINIO_CLEAN_BUCKET}' kh√¥ng t·ªìn t·∫°i!")
            st.info("üí° H√£y ch·∫°y quy tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu tr∆∞·ªõc.")
            return None
        
        st.success(f"‚úÖ K·∫øt n·ªëi MinIO th√†nh c√¥ng: {MINIO_HOST}")
        
        # T√¨m file combined
        combined_files = list_combined_files(client, MINIO_CLEAN_BUCKET)
        if not combined_files:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y file 'combined' trong MinIO!")
            st.info("üí° C√°c file c√≥ s·∫µn:")
            try:
                all_files = [obj.object_name for obj in client.list_objects(MINIO_CLEAN_BUCKET, recursive=True)]
                for file in all_files[:10]:  # Hi·ªÉn th·ªã 10 file ƒë·∫ßu ti√™n
                    st.write(f"   üìÑ {file}")
            except:
                pass
            return None
        
        # Load file ƒë·∫ßu ti√™n t√¨m ƒë∆∞·ª£c
        selected_file = combined_files[0]
        st.info(f"üìÅ ƒêang t·∫£i file: {selected_file}")
        
        df = load_csv_from_minio(client, MINIO_CLEAN_BUCKET, selected_file)
        
        if df is None:
            return None
            
        # Chu·∫©n h√≥a d·ªØ li·ªáu
        df = standardize_dataframe(df)
        
        st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {len(df):,} b·∫£n ghi t·ª´ MinIO")
        return df
        
    except Exception as e:
        st.error(f"‚ùå L·ªói khi k·∫øt n·ªëi MinIO: {e}")
        st.error("üîß Ki·ªÉm tra l·∫°i c·∫•u h√¨nh MinIO ho·∫∑c ƒë·∫£m b·∫£o server ƒëang ch·∫°y")
        return None

def standardize_dataframe(df):
    """Chu·∫©n h√≥a DataFrame t·ª´ MinIO"""
    try:
        # X·ª≠ l√Ω c·ªôt th·ªùi gian
        if 'ts_utc' in df.columns:
            df['date'] = pd.to_datetime(df['ts_utc'], errors='coerce')
        elif 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt th·ªùi gian (ts_utc ho·∫∑c date)")
            
        # T·∫°o c·ªôt month v√† year n·∫øu c√≥ c·ªôt date
        if 'date' in df.columns:
            df['month'] = df['date'].dt.month
            df['year'] = df['date'].dt.year
        
        # T·∫°o location_key n·∫øu ch∆∞a c√≥
        if 'location_key' not in df.columns:
            if 'location' in df.columns:
                df['location_key'] = df['location']
            else:
                # T·∫°o location_key gi·∫£ ƒë·ªãnh
                df['location_key'] = 'LOC001'
                st.info("‚ÑπÔ∏è T·∫°o location_key m·∫∑c ƒë·ªãnh: LOC001")
        
        # Ki·ªÉm tra v√† t·∫°o c√°c c·ªôt c·∫ßn thi·∫øt
        required_columns = ['aqi', 'pm25', 'pm10', 'no2', 'so2', 'co', 'o3']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.warning(f"‚ö†Ô∏è Thi·∫øu c√°c c·ªôt: {missing_columns}")
            # Kh√¥ng t·∫°o d·ªØ li·ªáu gi·∫£, ch·ªâ th√¥ng b√°o
        
        # T·∫°o c√°c c·ªôt AQI ph·ª• n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu g·ªëc
        aqi_mappings = {
            'aqi_pm25': ('pm25', 2.1),
            'aqi_pm10': ('pm10', 1.2), 
            'aqi_no2': ('no2', 1.8),
            'aqi_o3': ('o3', 1.1),
            'aqi_so2': ('so2', 2.5),
            'aqi_co': ('co', 25)
        }
        
        for aqi_col, (source_col, multiplier) in aqi_mappings.items():
            if source_col in df.columns and aqi_col not in df.columns:
                df[aqi_col] = df[source_col] * multiplier
        
        # Th√™m c√°c c·ªôt b·ªï sung n·∫øu ch∆∞a c√≥
        additional_cols = ['aod', 'dust', 'uv_index', 'co2']
        for col in additional_cols:
            if col not in df.columns:
                # Kh√¥ng t·∫°o d·ªØ li·ªáu gi·∫£, ch·ªâ th√¥ng b√°o thi·∫øu
                pass
        
        st.info(f"üìä C√°c c·ªôt c√≥ s·∫µn: {list(df.columns)}")
        return df
        
    except Exception as e:
        st.error(f"‚ùå L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {e}")
        return df

def bai_toan_1_phan_vung_o_nhiem(df):
    """B√ÄI TO√ÅN 1 ‚Äî PH√ÇN V√ôNG √î NHI·ªÑM & X·∫æP H·∫†NG T·ªàNH"""
    st.header("üè≠ B√ÄI TO√ÅN 1 ‚Äî PH√ÇN V√ôNG √î NHI·ªÑM & X·∫æP H·∫†NG T·ªàNH")

    # T√≠nh to√°n ranking theo month + year
    df_rank = (
        df.groupby(['location_key', 'month', 'year'])
        .agg(
            avg_aqi=('aqi', 'mean'),
            max_aqi=('aqi', 'max'),
            avg_pm25=('pm25', 'mean'),
            median_pm25=('pm25', 'median'),
            exceedance_days=('aqi', lambda x: (x > 100).sum()),
            data_completeness=('aqi', lambda x: x.count()/len(x)*100)
        )
        .reset_index()
    )

    df_rank['air_quality_score'] = (100 - df_rank['avg_aqi']/500*100) * (df_rank['data_completeness']/100)
    df_rank['rank'] = df_rank['avg_aqi'].rank(method='dense').astype(int)

    # Summary ranking table (to√†n b·ªô t·ªânh th√†nh)
    st.subheader("üèÜ B·∫£ng X·∫øp H·∫°ng T·ªïng Th·ªÉ T·∫•t C·∫£ T·ªânh Th√†nh")
    ranking_summary_all = (
        df_rank.groupby('location_key')
        .agg({
            'avg_aqi': 'mean',
            'air_quality_score': 'mean',
            'exceedance_days': 'sum'
        })
        .round(2)
        .sort_values('avg_aqi')
    )
    ranking_summary_all['rank'] = range(1, len(ranking_summary_all) + 1)
    st.dataframe(ranking_summary_all, use_container_width=True)

    # Top 10 Rankings
    st.subheader("ü•á Top 10 T·ªânh Th√†nh Theo Ch·∫•t L∆∞·ª£ng Kh√¥ng Kh√≠")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Top 10 t·ªânh √¥ nhi·ªÖm nh·∫•t
        st.write("**üî¥ Top 10 T·ªânh √î Nhi·ªÖm N·∫∑ng Nh·∫•t**")
        top_polluted = ranking_summary_all.nlargest(10, 'avg_aqi')[['avg_aqi', 'air_quality_score', 'exceedance_days']]
        top_polluted.columns = ['AQI TB', 'ƒêi·ªÉm Ch·∫•t L∆∞·ª£ng', 'Ng√†y V∆∞·ª£t Chu·∫©n']
        
        # Th√™m icon v√† m√†u s·∫Øc c·∫£nh b√°o
        top_polluted_display = top_polluted.copy()
        top_polluted_display.index = [f"üö® {idx}" for idx in top_polluted_display.index]
        
        st.dataframe(
            top_polluted_display.style.background_gradient(subset=['AQI TB'], cmap='Reds'),
            use_container_width=True
        )
    
    with col2:
        # Top 10 t·ªânh s·∫°ch nh·∫•t
        st.write("**üü¢ Top 10 T·ªânh Kh√¥ng Kh√≠ S·∫°ch Nh·∫•t**")
        top_clean = ranking_summary_all.nsmallest(10, 'avg_aqi')[['avg_aqi', 'air_quality_score', 'exceedance_days']]
        top_clean.columns = ['AQI TB', 'ƒêi·ªÉm Ch·∫•t L∆∞·ª£ng', 'Ng√†y V∆∞·ª£t Chu·∫©n']
        
        # Th√™m icon v√† m√†u s·∫Øc t√≠ch c·ª±c
        top_clean_display = top_clean.copy()
        top_clean_display.index = [f"‚úÖ {idx}" for idx in top_clean_display.index]
        
        st.dataframe(
            top_clean_display.style.background_gradient(subset=['AQI TB'], cmap='Greens_r'),
            use_container_width=True
        )
    
    # Th·ªëng k√™ so s√°nh
    st.write("**üìä So S√°nh Gi·ªØa Hai Nh√≥m:**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        avg_polluted = top_polluted['AQI TB'].mean()
        avg_clean = top_clean['AQI TB'].mean()
        difference = avg_polluted - avg_clean
        st.metric(
            "Ch√™nh L·ªách AQI TB",
            f"{difference:.1f}",
            delta=f"{(difference/avg_clean*100):+.1f}%"
        )
    
    with col2:
        max_exceedance = top_polluted['Ng√†y V∆∞·ª£t Chu·∫©n'].max()
        min_exceedance = top_clean['Ng√†y V∆∞·ª£t Chu·∫©n'].min()
        st.metric(
            "Ng√†y V∆∞·ª£t Chu·∫©n (Max vs Min)",
            f"{max_exceedance:.0f} vs {min_exceedance:.0f}",
            delta=f"Ch√™nh {max_exceedance-min_exceedance:.0f} ng√†y"
        )
    
    with col3:
        quality_diff = top_clean['ƒêi·ªÉm Ch·∫•t L∆∞·ª£ng'].mean() - top_polluted['ƒêi·ªÉm Ch·∫•t L∆∞·ª£ng'].mean()
        st.metric(
            "ƒêi·ªÉm Ch·∫•t L∆∞·ª£ng (S·∫°ch - √î nhi·ªÖm)",
            f"{quality_diff:+.1f}",
            delta="S·∫°ch h∆°n" if quality_diff > 0 else "K√©m h∆°n"
        )

    # Sidebar / selection: ch·ªçn t·ªânh(s) v√† nƒÉm ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    st.write("**üîé L·ªçc cho bi·ªÉu ƒë·ªì ph√¢n t√≠ch (gi√∫p tr·ª±c quan d·ªÖ ƒë·ªçc):**")
    available_locations = sorted(df_rank['location_key'].unique())
    selected_locations = st.multiselect("Ch·ªçn ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ so s√°nh:", options=available_locations, default=available_locations[:5])

    available_years = sorted(df_rank['year'].unique())
    selected_years = st.multiselect("Ch·ªçn nƒÉm ƒë·ªÉ hi·ªÉn th·ªã:", options=available_years, default=available_years)

    # L·ªçc df_rank theo l·ª±a ch·ªçn (ch·ªâ cho bi·ªÉu ƒë·ªì)
    df_rank_filt = df_rank[df_rank['location_key'].isin(selected_locations) & df_rank['year'].isin(selected_years)]

    # Summary cho bi·ªÉu ƒë·ªì
    ranking_summary = (
        df_rank_filt.groupby('location_key')
        .agg({
            'avg_aqi': 'mean',
            'air_quality_score': 'mean',
            'exceedance_days': 'sum'
        })
        .round(2)
        .sort_values('avg_aqi')
    )

    # Ph√¢n v√πng √¥ nhi·ªÖm theo m·ª©c ƒë·ªô
    st.subheader("üó∫Ô∏è Ph√¢n V√πng √î Nhi·ªÖm Theo M·ª©c ƒê·ªô")
    
    if len(df_rank_filt) == 0:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu cho l·ª±a ch·ªçn n√†y.")
    else:
        # Ph√¢n lo·∫°i c√°c v√πng theo m·ª©c ƒë·ªô √¥ nhi·ªÖm
        def classify_pollution_zone(aqi):
            if aqi <= 50: return "üü¢ V√πng S·∫°ch"
            elif aqi <= 100: return "üü° V√πng Trung B√¨nh"
            elif aqi <= 150: return "üü† V√πng √î Nhi·ªÖm"
            elif aqi <= 200: return "üî¥ V√πng Nguy Hi·ªÉm"
            else: return "üü£ V√πng C·ª±c Nguy Hi·ªÉm"
        
        # T√≠nh ph√¢n v√πng cho t·ª´ng ƒë·ªãa ƒëi·ªÉm
        zone_analysis = (
            df_rank_filt.groupby('location_key')['avg_aqi']
            .mean()
            .reset_index()
        )
        zone_analysis['pollution_zone'] = zone_analysis['avg_aqi'].apply(classify_pollution_zone)
        zone_analysis = zone_analysis.sort_values('avg_aqi')
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Bi·ªÉu ƒë·ªì ph√¢n b·ªë v√πng √¥ nhi·ªÖm
            zone_counts = zone_analysis['pollution_zone'].value_counts()
            
            fig_zone = px.pie(
                values=zone_counts.values,
                names=zone_counts.index,
                title="Ph√¢n B·ªë C√°c V√πng √î Nhi·ªÖm",
                color_discrete_sequence=['#2E8B57', '#FFD700', '#FF8C00', '#FF4500', '#8B008B']
            )
            st.plotly_chart(fig_zone, use_container_width=True)
            
            # Th·ªëng k√™ v√πng √¥ nhi·ªÖm
            st.write("**üìä Th·ªëng K√™ Ph√¢n V√πng:**")
            for zone, count in zone_counts.items():
                percentage = (count / len(zone_analysis)) * 100
                st.write(f"{zone}: {count} ƒë·ªãa ƒëi·ªÉm ({percentage:.1f}%)")
        
        with col2:
            # Bi·ªÉu ƒë·ªì AQI theo t·ª´ng ƒë·ªãa ƒëi·ªÉm v·ªõi m√†u s·∫Øc theo v√πng
            zone_colors = {
                "üü¢ V√πng S·∫°ch": "#2E8B57",
                "üü° V√πng Trung B√¨nh": "#FFD700", 
                "üü† V√πng √î Nhi·ªÖm": "#FF8C00",
                "üî¥ V√πng Nguy Hi·ªÉm": "#FF4500",
                "üü£ V√πng C·ª±c Nguy Hi·ªÉm": "#8B008B"
            }
            
            zone_analysis['color'] = zone_analysis['pollution_zone'].map(zone_colors)
            
            fig_aqi = px.bar(
                zone_analysis,
                x='location_key',
                y='avg_aqi',
                color='pollution_zone',
                color_discrete_map=zone_colors,
                title="AQI Trung B√¨nh Theo ƒê·ªãa ƒêi·ªÉm & V√πng √î Nhi·ªÖm"
            )
            
            # Th√™m ƒë∆∞·ªùng ng∆∞·ª°ng
            fig_aqi.add_hline(y=50, line_dash="dash", line_color="green", annotation_text="Ng∆∞·ª°ng T·ªët")
            fig_aqi.add_hline(y=100, line_dash="dash", line_color="orange", annotation_text="Ng∆∞·ª°ng Trung B√¨nh") 
            fig_aqi.add_hline(y=150, line_dash="dash", line_color="red", annotation_text="Ng∆∞·ª°ng K√©m")
            
            fig_aqi.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_aqi, use_container_width=True)
        
        # B·∫£ng chi ti·∫øt ph√¢n v√πng
        st.write("**üìã Chi Ti·∫øt Ph√¢n V√πng √î Nhi·ªÖm:**")
        zone_details = zone_analysis[['location_key', 'avg_aqi', 'pollution_zone']].copy()
        zone_details['avg_aqi'] = zone_details['avg_aqi'].round(2)
        zone_details.columns = ['ƒê·ªãa ƒêi·ªÉm', 'AQI Trung B√¨nh', 'Ph√¢n V√πng']
        st.dataframe(zone_details, use_container_width=True, hide_index=True)

    # Heatmap: use year-month as x axis to show month across years
    st.subheader("üìÖ Heatmap AQI Theo Th√°ng (k√®m NƒÉm) v√† ƒê·ªãa ƒêi·ªÉm")
    # build period string
    df_rank_filt['period'] = df_rank_filt['year'].astype(str) + '-' + df_rank_filt['month'].astype(str).str.zfill(2)
    pivot_data = df_rank_filt.pivot_table(values='avg_aqi', index='location_key', columns='period', aggfunc='mean')

    if pivot_data.empty:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu heatmap cho l·ª±a ch·ªçn n√†y.")
    else:
        # If too many locations selected, restrict to top 20 for readability
        max_locations = 20
        if len(pivot_data) > max_locations:
            st.warning(f"Qu√° nhi·ªÅu ƒë·ªãa ƒëi·ªÉm ({len(pivot_data)}). Hi·ªÉn th·ªã top {max_locations} theo AQI trung b√¨nh.")
            display_idx = ranking_summary.head(max_locations).index
            pivot_display = pivot_data.loc[pivot_data.index.intersection(display_idx)]
        else:
            pivot_display = pivot_data

        # Ensure columns sorted chronologically
        pivot_display = pivot_display.reindex(sorted(pivot_display.columns), axis=1)

        fig_heatmap = px.imshow(
            pivot_display.values,
            labels=dict(x="Th·ªùi Gian (YYYY-MM)", y="ƒê·ªãa ƒêi·ªÉm", color="AQI Trung B√¨nh"),
            x=pivot_display.columns,
            y=pivot_display.index,
            color_continuous_scale="RdYlGn_r"
        )
        fig_heatmap.update_layout(height=400 + 20*len(pivot_display))
        st.plotly_chart(fig_heatmap, use_container_width=True)

    return df_rank

def bai_toan_2_chat_o_nhiem(df):
    """B√ÄI TO√ÅN 2 ‚Äî PH√ÇN T√çCH CH·∫§T √î NHI·ªÑM CH√çNH ·∫¢NH H∆Ø·ªûNG"""
    st.header("üß™ B√ÄI TO√ÅN 2 ‚Äî PH√ÇN T√çCH CH·∫§T √î NHI·ªÑM CH√çNH ·∫¢NH H∆Ø·ªûNG")
    
    # T√≠nh c√°c t·ª∑ l·ªá ch·∫•t √¥ nhi·ªÖm
    df_pollutant = df.copy()
    
    # C√°c t·ª∑ l·ªá quan tr·ªçng trong ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠
    pollutant_ratios = {}
    if 'pm25' in df.columns and 'pm10' in df.columns:
        pollutant_ratios['pm25_pm10_ratio'] = df_pollutant['pm25'] / df_pollutant['pm10']
    if 'no2' in df.columns and 'so2' in df.columns:
        pollutant_ratios['no2_so2_ratio'] = df_pollutant['no2'] / df_pollutant['so2']
    if 'co' in df.columns and 'no2' in df.columns:
        pollutant_ratios['co_no2_ratio'] = df_pollutant['co'] / df_pollutant['no2']
    if 'dust' in df.columns and 'pm25' in df.columns:
        pollutant_ratios['dust_pm25_ratio'] = df_pollutant['dust'] / df_pollutant['pm25']
    
    for ratio_name, ratio_values in pollutant_ratios.items():
        df_pollutant[ratio_name] = ratio_values
    
    # Ph√¢n t√≠ch ph√¢n b·ªë c√°c ch·∫•t √¥ nhi·ªÖm chi ti·∫øt
    st.subheader("üìä Ph√¢n B·ªë C√°c Ch·∫•t √î Nhi·ªÖm")
    
    # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ c√°c c·ªôt AQI c√≥ s·∫µn
    aqi_cols = ['aqi_pm25', 'aqi_pm10', 'aqi_no2', 'aqi_o3', 'aqi_so2', 'aqi_co']
    available_aqi_cols = [col for col in aqi_cols if col in df_pollutant.columns]
    
    st.info(f"üîç C√°c ch·ªâ s·ªë AQI c√≥ s·∫µn: {', '.join(available_aqi_cols)}")
    
    if available_aqi_cols:
        # T√≠nh ch·∫•t √¥ nhi·ªÖm ch√≠nh v√† th·ªëng k√™ ƒë·∫ßy ƒë·ªß
        df_pollutant['dominant_pollutant'] = df_pollutant[available_aqi_cols].idxmax(axis=1).str.replace('aqi_', '').str.upper()
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Ph√¢n t√≠ch ph√¢n b·ªë c√°c ch·∫•t √¥ nhi·ªÖm theo nhi·ªÅu ti√™u ch√≠
            
            # Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn ng∆∞·ª°ng
            st.write("**‚öôÔ∏è T√πy ch·ªçn ph√¢n t√≠ch:**")
            aqi_threshold = st.selectbox(
                "Ch·ªçn ng∆∞·ª°ng AQI ƒë·ªÉ ph√¢n t√≠ch:",
                options=[50, 100, 150],
                index=0,
                format_func=lambda x: f"AQI > {x} ({'Trung b√¨nh' if x==50 else 'K√©m' if x==100 else 'R·∫•t k√©m'})"
            )
            
            # T·∫ßn su·∫•t v∆∞·ª£t ng∆∞·ª°ng (c√°ch ph√¢n t√≠ch h·ª£p l√Ω)
            threshold_exceed = {}
            
            for col in available_aqi_cols:
                pollutant_name = col.replace('aqi_', '').upper()
                exceed_count = (df_pollutant[col] > aqi_threshold).sum()
                threshold_exceed[pollutant_name] = exceed_count
            
            total_exceed = sum(threshold_exceed.values())
            
            if total_exceed == 0:
                st.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ ch·∫•t √¥ nhi·ªÖm n√†o v∆∞·ª£t ng∆∞·ª°ng AQI > {aqi_threshold}")
                exceed_percentages = {k: 0 for k in threshold_exceed.keys()}
            else:
                exceed_percentages = {k: (v/total_exceed*100) for k, v in threshold_exceed.items()}
                st.info(f"üìä T·ªïng s·ªë l·∫ßn v∆∞·ª£t ng∆∞·ª°ng: {total_exceed:,} l·∫ßn")
            
            # Bi·ªÉu ƒë·ªì tr√≤n - T·∫ßn su·∫•t v∆∞·ª£t ng∆∞·ª°ng AQI > 50
            fig_pie = px.pie(
                values=list(exceed_percentages.values()),
                names=list(exceed_percentages.keys()),
                title=f"% T·∫ßn Su·∫•t V∆∞·ª£t Ng∆∞·ª°ng AQI > {aqi_threshold}",
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            
            # T√πy ch·ªânh hi·ªÉn th·ªã ƒë·ªÉ th·∫•y r√µ c√°c ph·∫ßn nh·ªè
            fig_pie.update_traces(
                textposition='auto',  # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh v·ªã tr√≠ text
                texttemplate='%{label}<br>%{value:.5f}%',  # Hi·ªÉn th·ªã 5 ch·ªØ s·ªë th·∫≠p ph√¢n
                textfont_size=10,
                pull=[0.1 if v < 1 else 0 for v in exceed_percentages.values()]  # K√©o ra c√°c ph·∫ßn nh·ªè
            )
            st.plotly_chart(fig_pie, use_container_width=True)
            
            # Hi·ªÉn th·ªã b·∫£ng s·ªë li·ªáu chi ti·∫øt
            st.write(f"**üìä Ph√¢n T√≠ch V∆∞·ª£t Ng∆∞·ª°ng AQI > {aqi_threshold}:**")
            exceed_df = pd.DataFrame({
                'Ch·∫•t √î Nhi·ªÖm': list(exceed_percentages.keys()),
                f'S·ªë L·∫ßn > {aqi_threshold}': list(threshold_exceed.values()),
                '% T·∫ßn Su·∫•t': [f"{v:.5f}%" for v in exceed_percentages.values()],
                'AQI Trung B√¨nh': [df_pollutant[f'aqi_{k.lower()}'].mean().round(2) for k in exceed_percentages.keys()]
            })
            st.dataframe(exceed_df, use_container_width=True, hide_index=True)
            
 
        
        with col2:
            # Bi·ªÉu ƒë·ªì c·ªôt cho t·∫•t c·∫£ ch·∫•t √¥ nhi·ªÖm (gi√° tr·ªã trung b√¨nh AQI)
            aqi_means = df_pollutant[available_aqi_cols].mean()
            pollutant_names = [col.replace('aqi_', '').upper() for col in available_aqi_cols]
            
            fig_bar = px.bar(
                x=pollutant_names,
                y=aqi_means.values,
                title="M·ª©c AQI Trung B√¨nh T·∫•t C·∫£ Ch·∫•t √î Nhi·ªÖm",
                color=aqi_means.values,
                color_continuous_scale='Reds'
            )
            fig_bar.update_layout(
                xaxis_title="Ch·∫•t √î Nhi·ªÖm",
                yaxis_title="AQI Trung B√¨nh",
                showlegend=False
            )
            st.plotly_chart(fig_bar, use_container_width=True)
        
        # Th·ªëng k√™ chi ti·∫øt t·∫•t c·∫£ ch·∫•t √¥ nhi·ªÖm theo ng∆∞·ª°ng
        st.subheader("üìã Th·ªëng K√™ Chi Ti·∫øt Theo Ng∆∞·ª°ng")
        
        col3, col4 = st.columns(2)
        
        with col3:
            # B·∫£ng th·ªëng k√™ theo ng∆∞·ª°ng ƒë√£ ch·ªçn (s·ª≠ d·ª•ng l·∫°i aqi_threshold)
            st.write(f"**üìä Ph√¢n T√≠ch Theo Ng∆∞·ª°ng AQI > {aqi_threshold}:**")
            
            threshold_details = []
            for col in available_aqi_cols:
                pollutant_name = col.replace('aqi_', '').upper()
                exceed_count = (df_pollutant[col] > aqi_threshold).sum()
                total_records = len(df_pollutant)
                percentage = (exceed_count / total_records * 100) if total_records > 0 else 0
                
                threshold_details.append({
                    'Ch·∫•t √î Nhi·ªÖm': pollutant_name,
                    'S·ªë L·∫ßn V∆∞·ª£t': exceed_count,
                    'T·ªïng S·ªë M·∫´u': total_records,
                    '% V∆∞·ª£t Ng∆∞·ª°ng': f"{percentage:.4f}%"
                })
            
            threshold_df = pd.DataFrame(threshold_details)
            
            # Th√™m m√¥ t·∫£
            pollutant_descriptions = {
                'PM25': 'B·ª•i m·ªãn < 2.5Œºm',
                'PM10': 'B·ª•i m·ªãn < 10Œºm', 
                'NO2': 'Nitro dioxide',
                'O3': 'Ozone',
                'SO2': 'L∆∞u hu·ª≥nh dioxide',
                'CO': 'Carbon monoxide'
            }
            threshold_df['M√¥ T·∫£'] = threshold_df['Ch·∫•t √î Nhi·ªÖm'].map(pollutant_descriptions).fillna('Kh√¥ng r√µ')
            
            st.dataframe(threshold_df, use_container_width=True, hide_index=True)
        
        with col4:
            # B·∫£ng th·ªëng k√™ AQI trung b√¨nh v√† so s√°nh v·ªõi ng∆∞·ª°ng
            st.write("**üìà M·ª©c AQI Trung B√¨nh So V·ªõi Ng∆∞·ª°ng:**")
            
            all_aqi_stats = pd.DataFrame({
                'Ch·∫•t √î Nhi·ªÖm': [col.replace('aqi_', '').upper() for col in available_aqi_cols],
                'AQI TB': [df_pollutant[col].mean().round(2) for col in available_aqi_cols],
                'AQI Max': [df_pollutant[col].max().round(2) for col in available_aqi_cols],
                'Ng∆∞·ª°ng': aqi_threshold
            })
            
            # Th√™m ƒë√°nh gi√° so v·ªõi ng∆∞·ª°ng
            def compare_with_threshold(avg_val, threshold_val):
                if avg_val < threshold_val * 0.5: return "‚úÖ R·∫•t t·ªët"
                elif avg_val < threshold_val: return "‚ö†Ô∏è Ch·∫•p nh·∫≠n"
                elif avg_val < threshold_val * 1.5: return "‚õî V∆∞·ª£t ng∆∞·ª°ng"
                else: return "üö® Nguy hi·ªÉm"
            
            all_aqi_stats['So S√°nh'] = all_aqi_stats.apply(
                lambda row: compare_with_threshold(row['AQI TB'], row['Ng∆∞·ª°ng']), 
                axis=1
            )
            
            st.dataframe(all_aqi_stats, use_container_width=True, hide_index=True)
        
    else:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu AQI cho c√°c ch·∫•t √¥ nhi·ªÖm")
    
    # Ph√¢n t√≠ch m·ª©c ƒë·ªô c·ªßa t·ª´ng ch·∫•t √¥ nhi·ªÖm
    st.subheader("üìà M·ª©c ƒê·ªô C√°c Ch·∫•t √î Nhi·ªÖm Theo ƒê·ªãa ƒêi·ªÉm")
    
    # C√°c ch·∫•t √¥ nhi·ªÖm ch√≠nh c·∫ßn ph√¢n t√≠ch
    main_pollutants = ['pm25', 'pm10', 'no2', 'so2', 'co', 'o3']
    available_pollutants = [p for p in main_pollutants if p in df_pollutant.columns]
    
    if available_pollutants:
        # Th√™m t√πy ch·ªçn l·ªçc ƒë·ªãa ƒëi·ªÉm
        st.write("**üîé L·ªçc ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ ph√¢n t√≠ch:**")
        all_locations = sorted(df_pollutant['location_key'].unique())
        selected_locations_pollutant = st.multiselect(
            "Ch·ªçn ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ hi·ªÉn th·ªã:", 
            options=all_locations, 
            default=all_locations[:5],  # M·∫∑c ƒë·ªãnh 5 ƒë·ªãa ƒëi·ªÉm ƒë·∫ßu ti√™n
            key="pollutant_location_filter"
        )
        
        # N·∫øu kh√¥ng ch·ªçn g√¨ th√¨ hi·ªÉn th·ªã t·∫•t c·∫£
        if not selected_locations_pollutant:
            selected_locations_pollutant = all_locations
        
        # L·ªçc d·ªØ li·ªáu theo ƒë·ªãa ƒëi·ªÉm ƒë√£ ch·ªçn
        df_pollutant_filtered = df_pollutant[df_pollutant['location_key'].isin(selected_locations_pollutant)]
        
        # T√≠nh gi√° tr·ªã trung b√¨nh theo ƒë·ªãa ƒëi·ªÉm
        pollutant_by_location = df_pollutant_filtered.groupby('location_key')[available_pollutants].mean().reset_index()
        
        # Hi·ªÉn th·ªã th√¥ng tin s·ªë l∆∞·ª£ng ƒë·ªãa ƒëi·ªÉm ƒë√£ ch·ªçn
        st.info(f"üìä ƒêang hi·ªÉn th·ªã {len(selected_locations_pollutant)} / {len(all_locations)} ƒë·ªãa ƒëi·ªÉm")
        
        # T·∫°o bi·ªÉu ƒë·ªì ri√™ng cho t·ª´ng ch·∫•t √¥ nhi·ªÖm ƒë·ªÉ tr√°nh ch·ªìng ch√©o
        cols_per_row = 2  # 2 c·ªôt m·ªói h√†ng
        for i in range(0, len(available_pollutants), cols_per_row):
            cols = st.columns(cols_per_row)
            
            for j in range(cols_per_row):
                if i + j < len(available_pollutants):
                    pollutant = available_pollutants[i + j]
                    
                    with cols[j]:
                        # T·∫°o bi·ªÉu ƒë·ªì ri√™ng cho t·ª´ng ch·∫•t
                        fig_single = px.bar(
                            pollutant_by_location,
                            x='location_key',
                            y=pollutant,
                            title=f"M·ª©c {pollutant.upper()} Trung B√¨nh",
                            color=pollutant,
                            color_continuous_scale='Reds'
                        )
                        
                        fig_single.update_layout(
                            height=400,
                            xaxis_tickangle=-45,
                            xaxis_title="ƒê·ªãa ƒêi·ªÉm",
                            yaxis_title=f"{pollutant.upper()} (Œºg/m¬≥)",
                            showlegend=False
                        )
                        
                        st.plotly_chart(fig_single, use_container_width=True)
    
    # Bi·ªÉu ƒë·ªì t·ª∑ l·ªá c√°c ch·∫•t √¥ nhi·ªÖm (n·∫øu c√≥ d·ªØ li·ªáu)
    if pollutant_ratios:
        st.subheader("‚öñÔ∏è T·ª∑ L·ªá Gi·ªØa C√°c Ch·∫•t √î Nhi·ªÖm")
        
        # S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ l·ªçc theo ƒë·ªãa ƒëi·ªÉm ƒë√£ ch·ªçn
        ratio_data = df_pollutant_filtered.groupby('location_key')[list(pollutant_ratios.keys())].mean().reset_index()
        
        # T√™n hi·ªÉn th·ªã th√¢n thi·ªán h∆°n
        ratio_titles = {
            'pm25_pm10_ratio': 'PM2.5/PM10',
            'no2_so2_ratio': 'NO2/SO2', 
            'co_no2_ratio': 'CO/NO2',
            'dust_pm25_ratio': 'B·ª•i/PM2.5'
        }
        
        available_ratios = [k for k in pollutant_ratios.keys() if k in ratio_data.columns]
        
        if available_ratios:
            # T·∫°o bi·ªÉu ƒë·ªì ri√™ng cho t·ª´ng t·ª∑ l·ªá ƒë·ªÉ tr√°nh ch·ªìng ch√©o
            cols_per_row = 2  # 2 c·ªôt m·ªói h√†ng
            colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']
            
            for i in range(0, len(available_ratios), cols_per_row):
                cols = st.columns(cols_per_row)
                
                for j in range(cols_per_row):
                    if i + j < len(available_ratios):
                        ratio_col = available_ratios[i + j]
                        ratio_title = ratio_titles.get(ratio_col, ratio_col)
                        
                        with cols[j]:
                            # T·∫°o bi·ªÉu ƒë·ªì ri√™ng cho t·ª´ng t·ª∑ l·ªá
                            fig_single_ratio = px.bar(
                                ratio_data,
                                x='location_key',
                                y=ratio_col,
                                title=f"T·ª∑ L·ªá {ratio_title}",
                                color=ratio_col,
                                color_continuous_scale='Viridis'
                            )
                            
                            fig_single_ratio.update_layout(
                                height=400,
                                xaxis_tickangle=-45,
                                xaxis_title="ƒê·ªãa ƒêi·ªÉm",
                                yaxis_title=f"T·ª∑ L·ªá {ratio_title}",
                                showlegend=False
                            )
                            
                            st.plotly_chart(fig_single_ratio, use_container_width=True)
            
            # Gi·∫£i th√≠ch √Ω nghƒ©a c·ªßa c√°c t·ª∑ l·ªá
            with st.expander("üí° √ù Nghƒ©a C·ªßa C√°c T·ª∑ L·ªá"):
                st.markdown("""
                - **PM2.5/PM10**: T·ª∑ l·ªá b·ª•i m·ªãn si√™u nh·ªè so v·ªõi b·ª•i th√¥ng th∆∞·ªùng (c√†ng cao c√†ng nguy hi·ªÉm)
                - **NO2/SO2**: T·ª∑ l·ªá gi·ªØa kh√≠ th·∫£i giao th√¥ng v√† c√¥ng nghi·ªáp
                - **CO/NO2**: Ch·ªâ s·ªë ƒë·ªët ch√°y kh√¥ng ho√†n to√†n
                - **B·ª•i/PM2.5**: T·ª∑ l·ªá b·ª•i t·ª± nhi√™n v√† b·ª•i nh√¢n t·∫°o
                """)
    
    # Th·ªëng k√™ t·ªïng qu√°t v·ªÅ m·ª©c ƒë·ªô √¥ nhi·ªÖm
    st.subheader("üìã ƒê√°nh Gi√° T·ªïng Qu√°t M·ª©c ƒê·ªô √î Nhi·ªÖm")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'aqi' in df.columns:
            avg_aqi = df['aqi'].mean()
            aqi_status = "T·ªët" if avg_aqi <= 50 else "Trung b√¨nh" if avg_aqi <= 100 else "K√©m"
            st.metric("AQI Trung B√¨nh", f"{avg_aqi:.1f}", delta=aqi_status)
    
    with col2:
        if 'pm25' in df.columns:
            avg_pm25 = df['pm25'].mean()
            pm25_status = "An to√†n" if avg_pm25 <= 12 else "C·∫£nh b√°o" if avg_pm25 <= 35 else "Nguy hi·ªÉm"
            st.metric("PM2.5 Trung B√¨nh (Œºg/m¬≥)", f"{avg_pm25:.1f}", delta=pm25_status)
    
    with col3:
        if available_aqi_cols:
            most_common = df_pollutant['dominant_pollutant'].mode()[0]
            st.metric("Ch·∫•t √î Nhi·ªÖm Ch√≠nh", most_common, delta="Th∆∞·ªùng xuy√™n nh·∫•t")
    
    return df_pollutant

def bai_toan_3_xu_huong(df):
    """B√ÄI TO√ÅN 3 ‚Äî PH√ÇN T√çCH XU H∆Ø·ªöNG & T√ÅC ƒê·ªòNG S·ª∞ KI·ªÜN"""
    st.header("üìà B√ÄI TO√ÅN 3 ‚Äî PH√ÇN T√çCH XU H∆Ø·ªöNG & T√ÅC ƒê·ªòNG S·ª∞ KI·ªÜN")
    
    # T√≠nh xu h∆∞·ªõng
    df_trend = (
        df.groupby(['location_key','month','year'])
        .agg(pm25_current=('pm25','mean'))
        .reset_index()
        .sort_values(['location_key','year','month'])
    )
    
    df_trend['pm25_prev'] = df_trend.groupby('location_key')['pm25_current'].shift(1)
    df_trend['pm25_mom_change'] = (df_trend['pm25_current'] - df_trend['pm25_prev']) / df_trend['pm25_prev'] * 100
    df_trend['pm25_3m_ma'] = df_trend.groupby('location_key')['pm25_current'].rolling(3).mean().reset_index(level=0, drop=True)
    
    # T√≠nh slope xu h∆∞·ªõng b·∫±ng Linear Regression
    trend_data = []
    for loc, group in df_trend.groupby('location_key'):
        X = np.arange(len(group)).reshape(-1,1)
        y = group['pm25_current'].values
        if len(y) > 1:
            model = LinearRegression().fit(X,y)
            trend_data.append((loc, model.coef_[0], model.score(X, y)))
    
    trend_df = pd.DataFrame(trend_data, columns=['location_key','trend_slope', 'r_squared'])
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Xu H∆∞·ªõng PM2.5 Theo Th·ªùi Gian")
        
        # Hi·ªÉn th·ªã b·∫£ng xu h∆∞·ªõng
        trend_summary = trend_df.copy()
        trend_summary['xu_huong'] = trend_summary['trend_slope'].apply(
            lambda x: 'üìà TƒÉng' if x > 0.1 else 'üìâ Gi·∫£m' if x < -0.1 else '‚û°Ô∏è ·ªîn ƒë·ªãnh'
        )
        trend_summary['slope_round'] = trend_summary['trend_slope'].round(3)
        trend_summary['r2_round'] = trend_summary['r_squared'].round(3)
        
        st.dataframe(
            trend_summary[['location_key', 'xu_huong', 'slope_round', 'r2_round']],
            use_container_width=True
        )
    
    with col2:
        # Bi·ªÉu ƒë·ªì slope
        fig_slope = px.bar(
            trend_df, 
            x='location_key', 
            y='trend_slope',
            color='trend_slope',
            color_continuous_scale='RdYlGn_r',
            title="H·ªá S·ªë Xu H∆∞·ªõng PM2.5"
        )
        st.plotly_chart(fig_slope, use_container_width=True)
    
    # Bi·ªÉu ƒë·ªì xu h∆∞·ªõng theo th·ªùi gian
    st.subheader("üìÖ Bi·ªÉu ƒê·ªì Xu H∆∞·ªõng PM2.5 Chi Ti·∫øt")
    
    selected_locations = st.multiselect(
        "Ch·ªçn ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ hi·ªÉn th·ªã:",
        options=df_trend['location_key'].unique(),
        default=df_trend['location_key'].unique()[:3]
    )
    
    if selected_locations:
        fig_trend = go.Figure()
        
        for location in selected_locations:
            location_data = df_trend[df_trend['location_key'] == location]
            location_data['date_str'] = location_data['year'].astype(str) + '-' + location_data['month'].astype(str).str.zfill(2)
            
            # PM2.5 th·ª±c t·∫ø
            fig_trend.add_trace(
                go.Scatter(
                    x=location_data['date_str'],
                    y=location_data['pm25_current'],
                    mode='lines+markers',
                    name=f'{location} - PM2.5',
                    line=dict(width=2)
                )
            )
            
            # ƒê∆∞·ªùng trung b√¨nh ƒë·ªông 3 th√°ng
            fig_trend.add_trace(
                go.Scatter(
                    x=location_data['date_str'],
                    y=location_data['pm25_3m_ma'],
                    mode='lines',
                    name=f'{location} - MA(3)',
                    line=dict(width=1, dash='dash')
                )
            )
        
        fig_trend.update_layout(
            title="Xu H∆∞·ªõng PM2.5 v√† Trung B√¨nh ƒê·ªông 3 Th√°ng",
            xaxis_title="Th·ªùi Gian",
            yaxis_title="PM2.5 (¬µg/m¬≥)",
            height=500
        )
        st.plotly_chart(fig_trend, use_container_width=True)
    
    return df_trend, trend_df

@st.cache_data
def calculate_correlations(df):
    """T√≠nh ma tr·∫≠n t∆∞∆°ng quan v·ªõi cache ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô"""
    pollutants = ['pm25','pm10','o3','no2','so2','co','aod','dust','uv_index','co2']
    available_pollutants = [p for p in pollutants if p in df.columns]
    
    if len(available_pollutants) < 2:
        return pd.DataFrame(), pd.DataFrame()
    
    # T√≠nh ma tr·∫≠n t∆∞∆°ng quan t·ªïng th·ªÉ tr∆∞·ªõc (nhanh nh·∫•t)
    overall_corr = df[available_pollutants].corr()
    
    # T·ªëi ∆∞u h√≥a t√≠nh to√°n chi ti·∫øt
    correlation_data = []
    
    # Ch·ªâ t√≠nh cho c√°c ƒë·ªãa ƒëi·ªÉm c√≥ ƒë·ªß d·ªØ li·ªáu
    location_counts = df['location_key'].value_counts()
    valid_locations = location_counts[location_counts >= 50].index  # Ch·ªâ l·∫•y ƒë·ªãa ƒëi·ªÉm c√≥ √≠t nh·∫•t 50 b·∫£n ghi
    
    # Gi·ªõi h·∫°n s·ªë ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ tr√°nh qu√° ch·∫≠m
    if len(valid_locations) > 20:
        valid_locations = valid_locations[:20]  # Ch·ªâ l·∫•y 20 ƒë·ªãa ƒëi·ªÉm ƒë·∫ßu
    
    with st.spinner(f"ƒêang t√≠nh to√°n t∆∞∆°ng quan cho {len(valid_locations)} ƒë·ªãa ƒëi·ªÉm..."):
        # S·ª≠ d·ª•ng groupby thay v√¨ nested loops
        for location in valid_locations:
            location_data = df[df['location_key'] == location]
            
            # T√≠nh theo qu√Ω thay v√¨ th√°ng ƒë·ªÉ gi·∫£m t√≠nh to√°n
            location_data['quarter'] = location_data['month'].apply(lambda x: (x-1)//3 + 1)
            
            for quarter in location_data['quarter'].unique():
                subset = location_data[location_data['quarter'] == quarter]
                if len(subset) > 15:  # TƒÉng ng∆∞·ª°ng ƒë·ªÉ gi·∫£m t√≠nh to√°n
                    try:
                        corr_matrix = subset[available_pollutants].corr()
                        
                        # Ch·ªâ l·∫•y t∆∞∆°ng quan m·∫°nh ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc d·ªØ li·ªáu
                        for i, p1 in enumerate(available_pollutants):
                            for j, p2 in enumerate(available_pollutants[i+1:], i+1):
                                corr_val = corr_matrix.iloc[i, j]
                                if not pd.isna(corr_val) and abs(corr_val) > 0.3:  # Ch·ªâ l∆∞u t∆∞∆°ng quan > 0.3
                                    correlation_data.append({
                                        'location_key': location,
                                        'quarter': quarter,
                                        'pollutant_1': p1,
                                        'pollutant_2': p2,
                                        'correlation': round(corr_val, 3)
                                    })
                    except:
                        continue  # B·ªè qua n·∫øu c√≥ l·ªói
    
    df_corr = pd.DataFrame(correlation_data)
    return overall_corr, df_corr

def bai_toan_4_ma_tran_tuong_quan(df):
    """B√ÄI TO√ÅN 4 ‚Äî MA TR·∫¨N T∆Ø∆†NG QUAN CH·∫§T √î NHI·ªÑM"""
    st.header("üåç B√ÄI TO√ÅN 4 ‚Äî MA TR·∫¨N T∆Ø∆†NG QUAN CH·∫§T √î NHI·ªÑM N√ÇNG CAO")
    
    
    # T√≠nh to√°n v·ªõi cache
    overall_corr, df_corr = calculate_correlations(df)
    
    # ƒê·ªãnh nghƒ©a l·∫°i pollutants cho ph·∫ßn d∆∞·ªõi
    pollutants = ['pm25','pm10','o3','no2','so2','co','aod','dust','uv_index','co2']
    
    # T√¨m c√°c c·∫∑p t∆∞∆°ng quan m·∫°nh nh·∫•t
    strong_correlations = df_corr[abs(df_corr['correlation']) > 0.7] if not df_corr.empty else pd.DataFrame()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîó Top T∆∞∆°ng Quan M·∫°nh Nh·∫•t")
        if not strong_correlations.empty:
            top_correlations = (
                strong_correlations
                .groupby(['pollutant_1', 'pollutant_2'])['correlation']
                .mean()
                .reset_index()
                .sort_values('correlation', key=abs, ascending=False)
                .head(10)
            )
            
            fig_top_corr = px.bar(
                top_correlations,
                x='correlation',
                y=[f"{row['pollutant_1']} - {row['pollutant_2']}" for _, row in top_correlations.iterrows()],
                orientation='h',
                color='correlation',
                color_continuous_scale='RdBu',
                title="Top 10 T∆∞∆°ng Quan M·∫°nh Nh·∫•t"
            )
            st.plotly_chart(fig_top_corr, use_container_width=True)
        else:
            st.info("Kh√¥ng t√¨m th·∫•y t∆∞∆°ng quan m·∫°nh (>0.7)")
    
    with col2:
        st.subheader("üìç T∆∞∆°ng Quan Theo ƒê·ªãa ƒêi·ªÉm")
        
        available_pollutants_for_selection = [p for p in pollutants if p in df.columns]
        if len(available_pollutants_for_selection) >= 2:
            selected_pollutant_pair = st.selectbox(
                "Ch·ªçn c·∫∑p ch·∫•t √¥ nhi·ªÖm:",
                options=[f"{p1} - {p2}" for i, p1 in enumerate(available_pollutants_for_selection) for p2 in available_pollutants_for_selection[i+1:]],
                index=0
            )
        else:
            selected_pollutant_pair = None
        
        if selected_pollutant_pair and not df_corr.empty:
            p1, p2 = selected_pollutant_pair.split(' - ')
            
            location_corr = (
                df_corr[
                    (df_corr['pollutant_1'] == p1) & 
                    (df_corr['pollutant_2'] == p2)
                ]
                .groupby('location_key')['correlation']
                .mean()
                .reset_index()
            )
            
            if not location_corr.empty:
                fig_loc_corr = px.bar(
                    location_corr,
                    x='location_key',
                    y='correlation',
                    color='correlation',
                    color_continuous_scale='RdBu',
                    title=f"T∆∞∆°ng Quan {selected_pollutant_pair} Theo ƒê·ªãa ƒêi·ªÉm"
                )
                st.plotly_chart(fig_loc_corr, use_container_width=True)
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu t∆∞∆°ng quan cho c·∫∑p n√†y")
        elif not selected_pollutant_pair:
            st.info("Kh√¥ng ƒë·ªß ch·∫•t √¥ nhi·ªÖm ƒë·ªÉ ph√¢n t√≠ch")
    
    # Heatmap t∆∞∆°ng quan t·ªïng th·ªÉ
    st.subheader("üó∫Ô∏è Ma Tr·∫≠n T∆∞∆°ng Quan T·ªïng Th·ªÉ")
    
    # Ki·ªÉm tra ma tr·∫≠n t∆∞∆°ng quan t·ªïng th·ªÉ
    if overall_corr.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh ma tr·∫≠n t∆∞∆°ng quan t·ªïng th·ªÉ")
        return df_corr
    
    fig_overall = px.imshow(
        overall_corr.values,
        labels=dict(color="H·ªá s·ªë t∆∞∆°ng quan"),
        x=overall_corr.columns,
        y=overall_corr.columns,
        color_continuous_scale="RdBu",
        zmin=-1, zmax=1,
        title="Ma Tr·∫≠n T∆∞∆°ng Quan T·∫•t C·∫£ Ch·∫•t √î Nhi·ªÖm"
    )
    
    # Th√™m annotations
    for i in range(len(overall_corr)):
        for j in range(len(overall_corr.columns)):
            fig_overall.add_annotation(
                x=j, y=i,
                text=str(round(overall_corr.iloc[i, j], 2)),
                showarrow=False,
                font=dict(color="black" if abs(overall_corr.iloc[i, j]) < 0.5 else "white")
            )
    
    st.plotly_chart(fig_overall, use_container_width=True)
    
    # Ma tr·∫≠n t∆∞∆°ng quan ƒë·ªÉ download cho machine learning
    st.subheader("üì• T·∫£i Ma Tr·∫≠n T∆∞∆°ng Quan Cho Machine Learning")
    
    st.write("**üìä Ma Tr·∫≠n T∆∞∆°ng Quan T·ªïng Th·ªÉ:**")
    st.dataframe(overall_corr, use_container_width=True)
    
    # N√∫t download ma tr·∫≠n t·ªïng th·ªÉ
    csv_overall = overall_corr.to_csv()
    st.download_button(
        label="üì• T·∫£i Ma Tr·∫≠n T∆∞∆°ng Quan (CSV)",
        data=csv_overall,
        file_name=f"ma_tran_tuong_quan_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
        help="T·∫£i ma tr·∫≠n t∆∞∆°ng quan ƒë·ªÉ s·ª≠ d·ª•ng trong machine learning",
        use_container_width=True
    )
    
 
    
    return df_corr

def main():
    """H√†m ch√≠nh c·ªßa ·ª©ng d·ª•ng"""
    st.title("üåç Ph√¢n T√≠ch Ch·∫•t L∆∞·ª£ng Kh√¥ng Kh√≠ Chuy√™n S√¢u")
    st.markdown("---")
    
    # Sidebar cho navigation
    st.sidebar.title("üìã Menu Ph√¢n T√≠ch")
    analysis_option = st.sidebar.selectbox(
        "Ch·ªçn b√†i to√°n ph√¢n t√≠ch:",
        [
            "üìä T·ªïng Quan",
            "üè≠ B√†i 1: Ph√¢n V√πng & X·∫øp H·∫°ng",
            "üß™ B√†i 2: Ch·∫•t √î Nhi·ªÖm Ch√≠nh",
            "üìà B√†i 3: Xu H∆∞·ªõng & S·ª± Ki·ªán",
            "üåç B√†i 4: Ma Tr·∫≠n T∆∞∆°ng Quan",
            "üîç T·∫•t C·∫£ Ph√¢n T√≠ch"
        ]
    )
    
    # Load d·ªØ li·ªáu
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ MinIO..."):
        df = load_data()
    
    if df is None:
        st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ MinIO")
        st.markdown("""
        ### üîß H∆∞·ªõng d·∫´n kh·∫Øc ph·ª•c:
        1. **Ki·ªÉm tra MinIO server**: ƒê·∫£m b·∫£o MinIO ƒëang ch·∫°y t·∫°i `172.27.91.163:9004`
        2. **Ki·ªÉm tra bucket**: Bucket `air-quality-clean` ph·∫£i t·ªìn t·∫°i
        3. **Ki·ªÉm tra d·ªØ li·ªáu**: Ph·∫£i c√≥ file 'combined' trong `openmeteo/global/`
        4. **Ch·∫°y ti·ªÅn x·ª≠ l√Ω**: H√£y ch·∫°y quy tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu tr∆∞·ªõc
        """)
        return
    
    # Hi·ªÉn th·ªã th√¥ng tin t·ªïng quan
    if analysis_option == "üìä T·ªïng Quan":
        st.header("üìä T·ªïng Quan Ch·∫•t L∆∞·ª£ng Kh√¥ng Kh√≠")
        
        # Metrics ch√≠nh
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("T·ªïng s·ªë b·∫£n ghi", f"{len(df):,}")
        with col2:
            st.metric("S·ªë ƒë·ªãa ƒëi·ªÉm", df['location_key'].nunique())
        with col3:
            st.metric("Kho·∫£ng th·ªùi gian", f"{df['year'].min()} - {df['year'].max()}")
        with col4:
            avg_aqi = df['aqi'].mean()
            aqi_status = "T·ªët" if avg_aqi <= 50 else "Trung b√¨nh" if avg_aqi <= 100 else "K√©m"
            st.metric("AQI trung b√¨nh", f"{avg_aqi:.1f}", delta=aqi_status)
        
        # Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ t·ªïng th·ªÉ
        st.subheader("üåç T√¨nh Tr·∫°ng Ch·∫•t L∆∞·ª£ng Kh√¥ng Kh√≠")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Ph√¢n b·ªë AQI theo m·ª©c ƒë·ªô
            def classify_aqi(aqi):
                if aqi <= 50: return "üü¢ T·ªët"
                elif aqi <= 100: return "üü° Trung b√¨nh"  
                elif aqi <= 150: return "üü† K√©m"
                elif aqi <= 200: return "üî¥ R·∫•t k√©m"
                else: return "üü£ Nguy hi·ªÉm"
            
            df['aqi_level'] = df['aqi'].apply(classify_aqi)
            aqi_distribution = df['aqi_level'].value_counts()
            
            fig_aqi_dist = px.pie(
                values=aqi_distribution.values,
                names=aqi_distribution.index,
                title="Ph√¢n B·ªë M·ª©c ƒê·ªô AQI",
                color_discrete_sequence=['#2E8B57', '#FFD700', '#FF8C00', '#FF4500', '#8B008B']
            )
            st.plotly_chart(fig_aqi_dist, use_container_width=True)
        
        with col2:
            # Ph√¢n b·ªë AQI theo c√°c m·ª©c ng∆∞·ª°ng WHO
            aqi_thresholds = {
                'R·∫•t T·ªët (0-25)': len(df[df['aqi'] <= 25]),
                'T·ªët (26-50)': len(df[(df['aqi'] > 25) & (df['aqi'] <= 50)]),
                'Trung B√¨nh (51-100)': len(df[(df['aqi'] > 50) & (df['aqi'] <= 100)]),
                'K√©m (101-150)': len(df[(df['aqi'] > 100) & (df['aqi'] <= 150)]),
                'R·∫•t K√©m (151-200)': len(df[(df['aqi'] > 150) & (df['aqi'] <= 200)]),
                'Nguy Hi·ªÉm (>200)': len(df[df['aqi'] > 200])
            }
            
            fig_threshold = px.bar(
                x=list(aqi_thresholds.keys()),
                y=list(aqi_thresholds.values()),
                title="Ph√¢n B·ªë S·ªë Ng√†y Theo Ng∆∞·ª°ng AQI",
                color=list(aqi_thresholds.values()),
                color_continuous_scale='RdYlGn_r'
            )
            fig_threshold.update_layout(
                xaxis_title="M·ª©c ƒê·ªô AQI",
                yaxis_title="S·ªë Ng√†y",
                xaxis_tickangle=-45
            )
            st.plotly_chart(fig_threshold, use_container_width=True)
        
        # Th·ªëng k√™ c√°c ch·∫•t √¥ nhi·ªÖm ch√≠nh
        st.subheader("üß™ Th·ªëng K√™ C√°c Ch·∫•t √î Nhi·ªÖm")
        
        pollutants = ['pm25', 'pm10', 'no2', 'so2', 'co', 'o3']
        available_pollutants = [p for p in pollutants if p in df.columns]
        
        if available_pollutants:
            col1, col2, col3 = st.columns(3)
            
            for i, pollutant in enumerate(available_pollutants[:3]):
                with [col1, col2, col3][i]:
                    avg_val = df[pollutant].mean()
                    max_val = df[pollutant].max()
                    
                    # ƒê√°nh gi√° m·ª©c ƒë·ªô
                    if pollutant in ['pm25', 'pm10']:
                        status = "An to√†n" if avg_val <= 15 else "C·∫£nh b√°o" if avg_val <= 35 else "Nguy hi·ªÉm"
                    else:
                        status = "B√¨nh th∆∞·ªùng" if avg_val <= 40 else "Cao"
                    
                    st.metric(
                        f"{pollutant.upper()} TB (Œºg/m¬≥)",
                        f"{avg_val:.1f}",
                        delta=status
                    )
            
            # Bi·ªÉu ƒë·ªì so s√°nh c√°c ch·∫•t √¥ nhi·ªÖm
            pollutant_stats = df[available_pollutants].mean()
            
            fig_pollutants = px.bar(
                x=pollutant_stats.index,
                y=pollutant_stats.values,
                title="N·ªìng ƒê·ªô Trung B√¨nh C√°c Ch·∫•t √î Nhi·ªÖm",
                color=pollutant_stats.values,
                color_continuous_scale='Plasma'
            )
            fig_pollutants.update_layout(
                xaxis_title="Ch·∫•t √î Nhi·ªÖm",
                yaxis_title="N·ªìng ƒê·ªô Trung B√¨nh (Œºg/m¬≥)"
            )
            st.plotly_chart(fig_pollutants, use_container_width=True)
        
        # Xu h∆∞·ªõng theo th·ªùi gian
        st.subheader("üìà Xu H∆∞·ªõng Theo Th·ªùi Gian")
        
        # AQI theo th√°ng
        monthly_aqi = df.groupby(['year', 'month'])['aqi'].mean().reset_index()
        monthly_aqi['date'] = pd.to_datetime(monthly_aqi[['year', 'month']].assign(day=1))
        
        fig_trend = px.line(
            monthly_aqi,
            x='date',
            y='aqi',
            title="Xu H∆∞·ªõng AQI Theo Th·ªùi Gian",
            markers=True
        )
        fig_trend.update_layout(
            xaxis_title="Th·ªùi Gian",
            yaxis_title="AQI Trung B√¨nh"
        )
        st.plotly_chart(fig_trend, use_container_width=True)
        
        # Th·ªëng k√™ chi ti·∫øt to√†n di·ªán
        st.subheader("üìã Th·ªëng K√™ Chi Ti·∫øt To√†n Di·ªán")
        
        # T·∫°o 3 c·ªôt cho layout t·ªët h∆°n
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.write("**üéØ Ch·ªâ S·ªë Ch·∫•t L∆∞·ª£ng Kh√¥ng Kh√≠:**")
            
            # T√≠nh to√°n c√°c percentile
            aqi_p25 = df['aqi'].quantile(0.25)
            aqi_p75 = df['aqi'].quantile(0.75)
            aqi_median = df['aqi'].median()
            
            summary_stats = {
                "AQI trung b√¨nh": f"{df['aqi'].mean():.1f}",
                "AQI trung v·ªã": f"{aqi_median:.1f}",
                "AQI cao nh·∫•t": f"{df['aqi'].max():.1f}",
                "AQI th·∫•p nh·∫•t": f"{df['aqi'].min():.1f}",
                "Percentile 25%": f"{aqi_p25:.1f}",
                "Percentile 75%": f"{aqi_p75:.1f}",
                "ƒê·ªô l·ªách chu·∫©n": f"{df['aqi'].std():.1f}",
                "H·ªá s·ªë bi·∫øn thi√™n": f"{(df['aqi'].std()/df['aqi'].mean()*100):.1f}%"
            }
            
            for key, value in summary_stats.items():
                st.write(f"- **{key}**: {value}")
        
        with col2:
            st.write("**üö® Ph√¢n T√≠ch Ng∆∞·ª°ng Nguy Hi·ªÉm:**")
            
            # T√≠nh to√°n c√°c ng∆∞·ª°ng nguy hi·ªÉm
            danger_stats = {
                "% ng√†y AQI > 50 (Trung b√¨nh)": f"{(df['aqi'] > 50).mean()*100:.2f}%",
                "% ng√†y AQI > 100 (K√©m)": f"{(df['aqi'] > 100).mean()*100:.2f}%",
                "% ng√†y AQI > 150 (R·∫•t k√©m)": f"{(df['aqi'] > 150).mean()*100:.2f}%",
                "% ng√†y AQI > 200 (Nguy hi·ªÉm)": f"{(df['aqi'] > 200).mean()*100:.2f}%",
                "S·ªë ng√†y t·ªët (AQI ‚â§ 50)": f"{(df['aqi'] <= 50).sum():,}",
                "S·ªë ng√†y k√©m (AQI > 100)": f"{(df['aqi'] > 100).sum():,}",
                "Ng√†y √¥ nhi·ªÖm nh·∫•t": f"AQI {df['aqi'].max():.0f}",
                "T·∫ßn su·∫•t AQI > 100": f"1/{int(1/((df['aqi'] > 100).mean() + 0.0001))}"
            }
            
            for key, value in danger_stats.items():
                st.write(f"- **{key}**: {value}")
        
        with col3:
            st.write("**üìä Th√¥ng Tin C·∫•u Tr√∫c D·ªØ Li·ªáu:**")
            
            # Ph√¢n t√≠ch c·∫•u tr√∫c d·ªØ li·ªáu
            data_completeness = {}
            key_columns = ['aqi', 'pm25', 'pm10', 'no2', 'so2', 'co', 'o3']
            
            for col in key_columns:
                if col in df.columns:
                    completeness = (df[col].notna().sum() / len(df)) * 100
                    data_completeness[f"ƒê·∫ßy ƒë·ªß {col.upper()}"] = f"{completeness:.1f}%"
            
            # Th√¥ng tin t·ªïng quan
            general_info = {
                "T·ªïng s·ªë b·∫£n ghi": f"{len(df):,}",
                "S·ªë ƒë·ªãa ƒëi·ªÉm": f"{df['location_key'].nunique()}",
                "Kho·∫£ng th·ªùi gian": f"{df['year'].min()}-{df['year'].max()}",
                "S·ªë nƒÉm d·ªØ li·ªáu": f"{df['year'].nunique()}",
                "S·ªë th√°ng c√≥ d·ªØ li·ªáu": f"{df['month'].nunique()}/12",
                "Trung b√¨nh b·∫£n ghi/ƒë·ªãa ƒëi·ªÉm": f"{len(df)/df['location_key'].nunique():.0f}"
            }
            
            # Hi·ªÉn th·ªã th√¥ng tin chung
            for key, value in general_info.items():
                st.write(f"- **{key}**: {value}")
            
            st.write("\n**üìà ƒê·ªô ƒê·∫ßy ƒê·ªß D·ªØ Li·ªáu:**")
            for key, value in data_completeness.items():
                st.write(f"- **{key}**: {value}")
        
        # B·∫£ng th·ªëng k√™ m√¥ t·∫£ chi ti·∫øt
        st.subheader("üìà B·∫£ng Th·ªëng K√™ M√¥ T·∫£ C√°c Ch·ªâ S·ªë")
        
        # Ch·ªçn c√°c c·ªôt quan tr·ªçng ƒë·ªÉ hi·ªÉn th·ªã
        important_cols = ['aqi', 'pm25', 'pm10', 'no2', 'so2', 'co', 'o3']
        available_cols = [col for col in important_cols if col in df.columns]
        
        if available_cols:
            desc_stats = df[available_cols].describe().round(2)
            
            # Th√™m c√°c th·ªëng k√™ b·ªï sung
            additional_stats = pd.DataFrame({
                col: {
                    'missing_count': df[col].isna().sum(),
                    'missing_percent': (df[col].isna().sum() / len(df) * 100),
                    'unique_values': df[col].nunique(),
                    'skewness': df[col].skew(),
                    'kurtosis': df[col].kurtosis()
                } for col in available_cols
            }).T.round(2)
            
            # Hi·ªÉn th·ªã b·∫£ng m√¥ t·∫£ c∆° b·∫£n
            st.write("**üìä Th·ªëng K√™ C√°c Ch·ªâ S·ªë Ch·∫•t L∆∞·ª£ng Kh√¥ng Kh√≠:**")
            st.dataframe(desc_stats, use_container_width=True)
            
            # Gi·∫£i th√≠ch c√°c ch·ªâ s·ªë
            with st.expander("üí° Gi·∫£i Th√≠ch C√°c Ch·ªâ S·ªë Th·ªëng K√™"):
                st.markdown("""
                **√ù nghƒ©a c√°c ch·ªâ s·ªë trong b·∫£ng:**
                - **count**: S·ªë l∆∞·ª£ng ng√†y c√≥ d·ªØ li·ªáu ƒëo ƒë∆∞·ª£c
                - **mean**: N·ªìng ƒë·ªô trung b√¨nh c·ªßa ch·∫•t √¥ nhi·ªÖm
                - **std**: ƒê·ªô bi·∫øn ƒë·ªông c·ªßa ch·∫•t √¥ nhi·ªÖm (c√†ng cao c√†ng kh√¥ng ·ªïn ƒë·ªãnh)
                - **min/max**: N·ªìng ƒë·ªô th·∫•p nh·∫•t/cao nh·∫•t ghi nh·∫≠n ƒë∆∞·ª£c
                - **25%**: 25% ng√†y c√≥ n·ªìng ƒë·ªô th·∫•p h∆°n gi√° tr·ªã n√†y
                - **50%**: Gi√° tr·ªã trung v·ªã (50% ng√†y th·∫•p h∆°n, 50% cao h∆°n)
                - **75%**: 75% ng√†y c√≥ n·ªìng ƒë·ªô th·∫•p h∆°n gi√° tr·ªã n√†y
                
                **ƒê∆°n v·ªã ƒëo:**
                - **AQI**: Ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ (0-500, c√†ng th·∫•p c√†ng t·ªët)
                - **PM2.5, PM10, NO2, SO2, CO, O3**: Œºg/m¬≥ (microgram/m√©t kh·ªëi)
                """)
    
    # Ch·∫°y c√°c b√†i ph√¢n t√≠ch
    elif analysis_option == "üè≠ B√†i 1: Ph√¢n V√πng & X·∫øp H·∫°ng":
        bai_toan_1_phan_vung_o_nhiem(df)
    
    elif analysis_option == "üß™ B√†i 2: Ch·∫•t √î Nhi·ªÖm Ch√≠nh":
        bai_toan_2_chat_o_nhiem(df)
    
    elif analysis_option == "üìà B√†i 3: Xu H∆∞·ªõng & S·ª± Ki·ªán":
        bai_toan_3_xu_huong(df)
    
    elif analysis_option == "üåç B√†i 4: Ma Tr·∫≠n T∆∞∆°ng Quan":
        bai_toan_4_ma_tran_tuong_quan(df)
    
    elif analysis_option == "üîç T·∫•t C·∫£ Ph√¢n T√≠ch":
        st.info("üöÄ Ch·∫°y t·∫•t c·∫£ c√°c b√†i ph√¢n t√≠ch - c√≥ th·ªÉ m·∫•t v√†i ph√∫t...")
        
        df_rank = bai_toan_1_phan_vung_o_nhiem(df)
        st.markdown("---")
        
        df_pollutant = bai_toan_2_chat_o_nhiem(df)
        st.markdown("---")
        
        df_trend, trend_df = bai_toan_3_xu_huong(df)
        st.markdown("---")
        
        df_corr = bai_toan_4_ma_tran_tuong_quan(df)
        st.markdown("---")
        
        st.success("‚úÖ Ho√†n th√†nh t·∫•t c·∫£ ph√¢n t√≠ch!")

if __name__ == "__main__":
    main()
def run():
    # ƒë·ªÉ main.py c√≥ th·ªÉ g·ªçi module.run()
    main()